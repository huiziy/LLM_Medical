{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "542659e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f8b702",
   "metadata": {},
   "source": [
    "## Set Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66955960",
   "metadata": {},
   "outputs": [],
   "source": [
    "LF_result_path = \"\"\n",
    "LF_export_path = \"\"\n",
    "HY_result_path = \"/Users/huiziyu/Library/CloudStorage/GoogleDrive-huiziy@g.ucla.edu/My Drive/Project - LLM in Biomedical & Health/new/results\"\n",
    "HY_export_path = \"/Users/huiziyu/Library/CloudStorage/GoogleDrive-huiziy@g.ucla.edu/My Drive/Project - LLM in Biomedical & Health/new/results\"\n",
    "HY_import_path = \"/Users/huiziyu/Library/CloudStorage/GoogleDrive-huiziy@g.ucla.edu/My Drive/Project - LLM Bib in Biomedical & Health/data/processed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2cf5f0c8-4f91-4777-90fc-d55648dc7461",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_path = HY_result_path\n",
    "data_export_path = HY_export_path\n",
    "data_import_path = HY_import_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42c9f434",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_import_path+\"/relevant_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6cfdf4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace na with \"\"\n",
    "df.fillna(\"\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2285d9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "abstract_df = df[['display_name','doi','abstract_text']].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8300ac63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use title and abstract, as well focus on sentence-line context aware info, not keywords.\n",
    "abstract_df[\"Title_abstract\"] = abstract_df[\"display_name\"]+\". \"+abstract_df[\"abstract_text\"]\n",
    "# now titel only\n",
    "# abstract_df[\"Title_abstract\"] = abstract_df[\"display_name\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f390956",
   "metadata": {},
   "source": [
    "### Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f0131856",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertopic import BERTopic\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from umap import UMAP\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from hdbscan import HDBSCAN\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'mmr' from 'bertopic.representation._mmr' (/Users/huiziyu/opt/anaconda3/lib/python3.9/site-packages/bertopic/representation/_mmr.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m/Users/huiziyu/Dropbox/FALL_2023/ResearchCode/LLM_Medical/Analysis/BERTopic_for_content_analysis.ipynb Cell 11\u001b[0m line \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/huiziyu/Dropbox/FALL_2023/ResearchCode/LLM_Medical/Analysis/BERTopic_for_content_analysis.ipynb#X36sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mbertopic\u001b[39;00m \u001b[39mimport\u001b[39;00m BERTopic\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/bertopic/__init__.py:1\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mbertopic\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_bertopic\u001b[39;00m \u001b[39mimport\u001b[39;00m BERTopic\n\u001b[1;32m      3\u001b[0m __version__ \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m0.14.1\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      5\u001b[0m __all__ \u001b[39m=\u001b[39m [\n\u001b[1;32m      6\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mBERTopic\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      7\u001b[0m ]\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/bertopic/_bertopic.py:49\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mBERTopic\u001b[39;00m:\n\u001b[0;32m---> 49\u001b[0m     \u001b[39m\"\"\"BERTopic is a topic modeling technique that leverages BERT embeddings and\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[39m    c-TF-IDF to create dense clusters allowing for easily interpretable topics\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[39m    whilst keeping important words in the topic descriptions.\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \n\u001b[1;32m     53\u001b[0m \u001b[39m    The default embedding model is `all-MiniLM-L6-v2` when selecting `language=\"english\"`\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[39m    and `paraphrase-multilingual-MiniLM-L12-v2` when selecting `language=\"multilingual\"`.\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \n\u001b[1;32m     56\u001b[0m \u001b[39m    Attributes:\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[39m        topics_ (List[int]) : The topics that are generated for each document after training or updating\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[39m                              the topic model. The most recent topics are tracked.\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[39m        probabilities_ (List[float]): The probability of the assigned topic per document. These are\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[39m                                      only calculated if a HDBSCAN model is used for the clustering step.\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[39m                                      When `calculate_probabilities=True`, then it is the probabilities\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \u001b[39m                                      of all topics per document.\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[39m        topic_sizes_ (Mapping[int, int]) : The size of each topic\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39m        topic_mapper_ (TopicMapper) : A class for tracking topics and their mappings anytime they are\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \u001b[39m                                      merged, reduced, added, or removed.\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[39m        topic_representations_ (Mapping[int, Tuple[int, float]]) : The top n terms per topic and their respective\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[39m                                                                   c-TF-IDF values.\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[39m        c_tf_idf_ (csr_matrix) : The topic-term matrix as calculated through c-TF-IDF. To access its respective\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[39m                                 words, run `.vectorizer_model.get_feature_names()`  or\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[39m                                 `.vectorizer_model.get_feature_names_out()`\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39m        topic_labels_ (Mapping[int, str]) : The default labels for each topic.\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \u001b[39m        custom_labels_ (List[str]) : Custom labels for each topic.\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[39m        topic_embeddings_ (np.ndarray) : The embeddings for each topic. It is calculated by taking the\u001b[39;00m\n\u001b[1;32m     74\u001b[0m \u001b[39m                                         weighted average of word embeddings in a topic based on their c-TF-IDF values.\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[39m        representative_docs_ (Mapping[int, str]) : The representative documents for each topic.\u001b[39;00m\n\u001b[1;32m     76\u001b[0m \n\u001b[1;32m     77\u001b[0m \u001b[39m    Examples:\u001b[39;00m\n\u001b[1;32m     78\u001b[0m \n\u001b[1;32m     79\u001b[0m \u001b[39m    ```python\u001b[39;00m\n\u001b[1;32m     80\u001b[0m \u001b[39m    from bertopic import BERTopic\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[39m    from sklearn.datasets import fetch_20newsgroups\u001b[39;00m\n\u001b[1;32m     82\u001b[0m \n\u001b[1;32m     83\u001b[0m \u001b[39m    docs = fetch_20newsgroups(subset='all')['data']\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[39m    topic_model = BERTopic()\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \u001b[39m    topics, probabilities = topic_model.fit_transform(docs)\u001b[39;00m\n\u001b[1;32m     86\u001b[0m \u001b[39m    ```\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \n\u001b[1;32m     88\u001b[0m \u001b[39m    If you want to use your own embedding model, use it as follows:\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \n\u001b[1;32m     90\u001b[0m \u001b[39m    ```python\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[39m    from bertopic import BERTopic\u001b[39;00m\n\u001b[1;32m     92\u001b[0m \u001b[39m    from sklearn.datasets import fetch_20newsgroups\u001b[39;00m\n\u001b[1;32m     93\u001b[0m \u001b[39m    from sentence_transformers import SentenceTransformer\u001b[39;00m\n\u001b[1;32m     94\u001b[0m \n\u001b[1;32m     95\u001b[0m \u001b[39m    docs = fetch_20newsgroups(subset='all')['data']\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[39m    sentence_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[39m    topic_model = BERTopic(embedding_model=sentence_model)\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \u001b[39m    ```\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \n\u001b[1;32m    100\u001b[0m \u001b[39m    Due to the stochastisch nature of UMAP, the results from BERTopic might differ\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \u001b[39m    and the quality can degrade. Using your own embeddings allows you to\u001b[39;00m\n\u001b[1;32m    102\u001b[0m \u001b[39m    try out BERTopic several times until you find the topics that suit\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \u001b[39m    you best.\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m    105\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m,\n\u001b[1;32m    106\u001b[0m                  language: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39menglish\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    107\u001b[0m                  top_n_words: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m \u001b[39m10\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    120\u001b[0m                  verbose: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    121\u001b[0m                  ):\n\u001b[1;32m    122\u001b[0m         \u001b[39m\"\"\"BERTopic initialization\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \n\u001b[1;32m    124\u001b[0m \u001b[39m        Arguments:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[39m                                  are supported.\u001b[39;00m\n\u001b[1;32m    182\u001b[0m \u001b[39m        \"\"\"\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'mmr' from 'bertopic.representation._mmr' (/Users/huiziyu/opt/anaconda3/lib/python3.9/site-packages/bertopic/representation/_mmr.py)"
     ]
    }
   ],
   "source": [
    "from bertopic import BERTopic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-2.1.1-cp39-none-macosx_10_9_x86_64.whl (147.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.0/147.0 MB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: sympy in /Users/huiziyu/opt/anaconda3/lib/python3.9/site-packages (from torch) (1.10.1)\n",
      "Requirement already satisfied: fsspec in /Users/huiziyu/opt/anaconda3/lib/python3.9/site-packages (from torch) (2022.2.0)\n",
      "Requirement already satisfied: typing-extensions in /Users/huiziyu/opt/anaconda3/lib/python3.9/site-packages (from torch) (4.8.0)\n",
      "Requirement already satisfied: jinja2 in /Users/huiziyu/opt/anaconda3/lib/python3.9/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: networkx in /Users/huiziyu/opt/anaconda3/lib/python3.9/site-packages (from torch) (2.7.1)\n",
      "Requirement already satisfied: filelock in /Users/huiziyu/opt/anaconda3/lib/python3.9/site-packages (from torch) (3.6.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/huiziyu/opt/anaconda3/lib/python3.9/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/huiziyu/opt/anaconda3/lib/python3.9/site-packages (from sympy->torch) (1.2.1)\n",
      "Installing collected packages: torch\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchvision 0.13.1 requires torch==1.12.1, but you have torch 2.1.1 which is incompatible.\n",
      "farm-haystack 1.10.0 requires torch<1.13,>1.9, but you have torch 2.1.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed torch-2.1.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b8e05213",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [str(item) for item in list(abstract_df.Title_abstract)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71e809f",
   "metadata": {},
   "source": [
    "## Add additional stopwords based on the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "aee5da69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "\n",
    "# Your additional stop words\n",
    "additional_stop_words = {\"large language model\", \"GPT\", \"ChatGPT\", \"Llama\", \"Google Palm\", \"Anthropic Claude\", \"Large Language Model\", \"LLM\", \"Chatgpt\",\"health\", \"medical\", \"Health\", \"Medical\"}\n",
    "\n",
    "# Combine default English stop words with your additional ones\n",
    "custom_stop_words = list(ENGLISH_STOP_WORDS.union(additional_stop_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "577f2ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [TODO 1] need to consider remove query keywords\n",
    "# [TODO 2] remove non-English\n",
    "# [TODO 3] cluster number: more experiments [20, 30, 40, 50, 100, 150, 200]\n",
    "# 200 too many\n",
    "vectorizer_model = CountVectorizer(stop_words=custom_stop_words)\n",
    "# hdbscan_model = HDBSCAN(min_cluster_size=10,\n",
    "#                         min_samples=5,\n",
    "#                         metric='euclidean',\n",
    "#                         cluster_selection_method='eom',\n",
    "#                         prediction_data=True) # random_state=42\n",
    "cluster_model = KMeans(n_clusters=200)\n",
    "topic_model = BERTopic(hdbscan_model=cluster_model, #hdbscan_model,\n",
    "                       vectorizer_model=vectorizer_model,\n",
    "                       top_n_words=10) # nr_topics=100,\n",
    "topics, probs = topic_model.fit_transform(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "51c7664e",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.save(result_path+\"/LLM_en_title_200\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "59159644",
   "metadata": {},
   "outputs": [],
   "source": [
    "abstract_df[\"topics\"] = topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d80acec7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>display_name</th>\n",
       "      <th>doi</th>\n",
       "      <th>abstract_text</th>\n",
       "      <th>Title_abstract</th>\n",
       "      <th>topics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Performance of ChatGPT on USMLE: Potential for...</td>\n",
       "      <td>https://doi.org/10.1371/journal.pdig.0000198</td>\n",
       "      <td>We evaluated the performance of a large langua...</td>\n",
       "      <td>Performance of ChatGPT on USMLE: Potential for...</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How Does ChatGPT Perform on the United States ...</td>\n",
       "      <td>https://doi.org/10.2196/45312</td>\n",
       "      <td>Background Chat Generative Pre-trained Transfo...</td>\n",
       "      <td>How Does ChatGPT Perform on the United States ...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ChatGPT and the Future of Medical Writing</td>\n",
       "      <td>https://doi.org/10.1148/radiol.223312</td>\n",
       "      <td>HomeRadiologyVol. 307, No. 2 PreviousNext Revi...</td>\n",
       "      <td>ChatGPT and the Future of Medical Writing</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Performance of ChatGPT on USMLE: Potential for...</td>\n",
       "      <td>https://doi.org/10.1101/2022.12.19.22283643</td>\n",
       "      <td>ABSTRACT We evaluated the performance of a lar...</td>\n",
       "      <td>Performance of ChatGPT on USMLE: Potential for...</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Role of ChatGPT, Generative Language Model...</td>\n",
       "      <td>https://doi.org/10.2196/46885</td>\n",
       "      <td>ChatGPT is a generative language model tool la...</td>\n",
       "      <td>The Role of ChatGPT, Generative Language Model...</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3412</th>\n",
       "      <td>Revolutionizing clinical experimental protocol...</td>\n",
       "      <td>https://doi.org/10.1016/j.amjms.2023.09.004</td>\n",
       "      <td>ChatGPT is a conversational artificial intelli...</td>\n",
       "      <td>Revolutionizing clinical experimental protocol...</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3413</th>\n",
       "      <td>Applying GPT-4 to the Plastic Surgery Inservic...</td>\n",
       "      <td>https://doi.org/10.1016/j.bjps.2023.09.027</td>\n",
       "      <td>The recent introduction of Generative Pre-trai...</td>\n",
       "      <td>Applying GPT-4 to the Plastic Surgery Inservic...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3414</th>\n",
       "      <td>ChatGPT for low- and middle-income countries: ...</td>\n",
       "      <td>https://doi.org/10.1016/j.lanwpc.2023.100906</td>\n",
       "      <td>ChatGPT (OpenAI, San Francisco, CA, USA) has m...</td>\n",
       "      <td>ChatGPT for low- and middle-income countries: ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3415</th>\n",
       "      <td>Interpretable Disease Prediction via Path Reas...</td>\n",
       "      <td>https://doi.org/10.1016/j.knosys.2023.111082</td>\n",
       "      <td>Disease prediction based on patients’ historic...</td>\n",
       "      <td>Interpretable Disease Prediction via Path Reas...</td>\n",
       "      <td>175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3416</th>\n",
       "      <td>ChatGPT (Generated Pre-Trained Transformer) As...</td>\n",
       "      <td>https://doi.org/10.23937/2572-4037.1510062</td>\n",
       "      <td>Mental health disorders affect one in four peo...</td>\n",
       "      <td>ChatGPT (Generated Pre-Trained Transformer) As...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3417 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           display_name  \\\n",
       "0     Performance of ChatGPT on USMLE: Potential for...   \n",
       "1     How Does ChatGPT Perform on the United States ...   \n",
       "2             ChatGPT and the Future of Medical Writing   \n",
       "3     Performance of ChatGPT on USMLE: Potential for...   \n",
       "4     The Role of ChatGPT, Generative Language Model...   \n",
       "...                                                 ...   \n",
       "3412  Revolutionizing clinical experimental protocol...   \n",
       "3413  Applying GPT-4 to the Plastic Surgery Inservic...   \n",
       "3414  ChatGPT for low- and middle-income countries: ...   \n",
       "3415  Interpretable Disease Prediction via Path Reas...   \n",
       "3416  ChatGPT (Generated Pre-Trained Transformer) As...   \n",
       "\n",
       "                                               doi  \\\n",
       "0     https://doi.org/10.1371/journal.pdig.0000198   \n",
       "1                    https://doi.org/10.2196/45312   \n",
       "2            https://doi.org/10.1148/radiol.223312   \n",
       "3      https://doi.org/10.1101/2022.12.19.22283643   \n",
       "4                    https://doi.org/10.2196/46885   \n",
       "...                                            ...   \n",
       "3412   https://doi.org/10.1016/j.amjms.2023.09.004   \n",
       "3413    https://doi.org/10.1016/j.bjps.2023.09.027   \n",
       "3414  https://doi.org/10.1016/j.lanwpc.2023.100906   \n",
       "3415  https://doi.org/10.1016/j.knosys.2023.111082   \n",
       "3416    https://doi.org/10.23937/2572-4037.1510062   \n",
       "\n",
       "                                          abstract_text  \\\n",
       "0     We evaluated the performance of a large langua...   \n",
       "1     Background Chat Generative Pre-trained Transfo...   \n",
       "2     HomeRadiologyVol. 307, No. 2 PreviousNext Revi...   \n",
       "3     ABSTRACT We evaluated the performance of a lar...   \n",
       "4     ChatGPT is a generative language model tool la...   \n",
       "...                                                 ...   \n",
       "3412  ChatGPT is a conversational artificial intelli...   \n",
       "3413  The recent introduction of Generative Pre-trai...   \n",
       "3414  ChatGPT (OpenAI, San Francisco, CA, USA) has m...   \n",
       "3415  Disease prediction based on patients’ historic...   \n",
       "3416  Mental health disorders affect one in four peo...   \n",
       "\n",
       "                                         Title_abstract  topics  \n",
       "0     Performance of ChatGPT on USMLE: Potential for...      35  \n",
       "1     How Does ChatGPT Perform on the United States ...       6  \n",
       "2             ChatGPT and the Future of Medical Writing      60  \n",
       "3     Performance of ChatGPT on USMLE: Potential for...      35  \n",
       "4     The Role of ChatGPT, Generative Language Model...      35  \n",
       "...                                                 ...     ...  \n",
       "3412  Revolutionizing clinical experimental protocol...      28  \n",
       "3413  Applying GPT-4 to the Plastic Surgery Inservic...      16  \n",
       "3414  ChatGPT for low- and middle-income countries: ...       2  \n",
       "3415  Interpretable Disease Prediction via Path Reas...     175  \n",
       "3416  ChatGPT (Generated Pre-Trained Transformer) As...       7  \n",
       "\n",
       "[3417 rows x 5 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abstract_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4628e4a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "      <th>Representation</th>\n",
       "      <th>Representative_Docs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>0_education_blessing_reshaping_nursing</td>\n",
       "      <td>[education, blessing, reshaping, nursing, curs...</td>\n",
       "      <td>[The Utilization of ChatGPT in Reshaping Futur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>1_models_large_language_survey</td>\n",
       "      <td>[models, large, language, survey, ontology, in...</td>\n",
       "      <td>[Large Language Models: A Comprehensive Survey...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>52</td>\n",
       "      <td>2_visually_blind_trust_vs</td>\n",
       "      <td>[visually, blind, trust, vs, impaired, charact...</td>\n",
       "      <td>[ChatGPT for Visually Impaired and Blind, Chat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>3_fish_carp_growth_meal</td>\n",
       "      <td>[fish, carp, growth, meal, dietary, hematologi...</td>\n",
       "      <td>[Effect of white mulberry (Morus albas l.) On ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>48</td>\n",
       "      <td>4_higher_computer_students_student</td>\n",
       "      <td>[higher, computer, students, student, teaching...</td>\n",
       "      <td>[ChatGPT in higher education: Considerations f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>195</td>\n",
       "      <td>4</td>\n",
       "      <td>195_neurology_forecasting_2035_series</td>\n",
       "      <td>[neurology, forecasting, 2035, series, ipsycho...</td>\n",
       "      <td>[Editors' Note: Neurology Education in 2035: T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>196</td>\n",
       "      <td>3</td>\n",
       "      <td>196_davinci_chatgptenabled_prototype_robot</td>\n",
       "      <td>[davinci, chatgptenabled, prototype, robot, ad...</td>\n",
       "      <td>[Response of ChatGPT for Humanoid Robots Role ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>197</td>\n",
       "      <td>2</td>\n",
       "      <td>197_ernie_rush_bing_gold</td>\n",
       "      <td>[ernie, rush, bing, gold, war, chats, determin...</td>\n",
       "      <td>[Efficacy of AI Chats to Determine an Emergenc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>198</td>\n",
       "      <td>2</td>\n",
       "      <td>198_virtual_realism_processor_ab1701</td>\n",
       "      <td>[virtual, realism, processor, ab1701, prenatal...</td>\n",
       "      <td>[AB1701 HOW TO MAKE A VIRTUAL PRESENTATION USI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>199</td>\n",
       "      <td>1</td>\n",
       "      <td>199_industry_hotel_emergencies_tourism</td>\n",
       "      <td>[industry, hotel, emergencies, tourism, public...</td>\n",
       "      <td>[Analysis on the development and impact of pub...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Topic  Count                                        Name  \\\n",
       "0        0     72      0_education_blessing_reshaping_nursing   \n",
       "1        1     63              1_models_large_language_survey   \n",
       "2        2     52                   2_visually_blind_trust_vs   \n",
       "3        3     50                     3_fish_carp_growth_meal   \n",
       "4        4     48          4_higher_computer_students_student   \n",
       "..     ...    ...                                         ...   \n",
       "195    195      4       195_neurology_forecasting_2035_series   \n",
       "196    196      3  196_davinci_chatgptenabled_prototype_robot   \n",
       "197    197      2                    197_ernie_rush_bing_gold   \n",
       "198    198      2        198_virtual_realism_processor_ab1701   \n",
       "199    199      1      199_industry_hotel_emergencies_tourism   \n",
       "\n",
       "                                        Representation  \\\n",
       "0    [education, blessing, reshaping, nursing, curs...   \n",
       "1    [models, large, language, survey, ontology, in...   \n",
       "2    [visually, blind, trust, vs, impaired, charact...   \n",
       "3    [fish, carp, growth, meal, dietary, hematologi...   \n",
       "4    [higher, computer, students, student, teaching...   \n",
       "..                                                 ...   \n",
       "195  [neurology, forecasting, 2035, series, ipsycho...   \n",
       "196  [davinci, chatgptenabled, prototype, robot, ad...   \n",
       "197  [ernie, rush, bing, gold, war, chats, determin...   \n",
       "198  [virtual, realism, processor, ab1701, prenatal...   \n",
       "199  [industry, hotel, emergencies, tourism, public...   \n",
       "\n",
       "                                   Representative_Docs  \n",
       "0    [The Utilization of ChatGPT in Reshaping Futur...  \n",
       "1    [Large Language Models: A Comprehensive Survey...  \n",
       "2    [ChatGPT for Visually Impaired and Blind, Chat...  \n",
       "3    [Effect of white mulberry (Morus albas l.) On ...  \n",
       "4    [ChatGPT in higher education: Considerations f...  \n",
       "..                                                 ...  \n",
       "195  [Editors' Note: Neurology Education in 2035: T...  \n",
       "196  [Response of ChatGPT for Humanoid Robots Role ...  \n",
       "197  [Efficacy of AI Chats to Determine an Emergenc...  \n",
       "198  [AB1701 HOW TO MAKE A VIRTUAL PRESENTATION USI...  \n",
       "199  [Analysis on the development and impact of pub...  \n",
       "\n",
       "[200 rows x 5 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show topics info\n",
    "topic_model.get_topic_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "57d92ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.get_topic_info().to_csv(data_export_path+\"/LLM_en_openalex_title_topics_metadata_200.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "525ffa6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show Topic Positions -> suggestions for further clustering\n",
    "#topic_model.visualize_topics()\n",
    "fig_IDM = topic_model.visualize_topics()\n",
    "fig_IDM.write_html(result_path+\"/LLM_en_openalex_title_viz_IDM_200.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "78f4ac91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize Topic Hierarchy -> suggestions for further clustering\n",
    "fig_hierarchy = topic_model.visualize_hierarchy()\n",
    "fig_hierarchy.write_html(result_path+\"/LLM_en_openalex_title_viz_hierarchy_200.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c26055ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize words\n",
    "fig_topic_word_scores = topic_model.visualize_barchart(top_n_topics=32)\n",
    "fig_topic_word_scores.write_html(result_path+\"/LLM_en_openalex_title_viz_topic_word_scores_200.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9ef1ae66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize topic similarity -- not useful in our case, maybe include to show not correlated\n",
    "fig_heatmap = topic_model.visualize_heatmap()\n",
    "fig_heatmap.write_html(result_path+\"/LLM_en_openalex_title_viz_heatmap_200.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7ef4e2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize documents\n",
    "sentence_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "embeddings = sentence_model.encode(docs, show_progress_bar=False)\n",
    "# Run the visualization with the original embeddings\n",
    "topic_model.visualize_documents(docs, embeddings=embeddings)\n",
    "# Reduce dimensionality of embeddings, this step is optional but much faster to perform iteratively:\n",
    "reduced_embeddings = UMAP(n_neighbors=10, n_components=2, min_dist=0.0, metric='cosine').fit_transform(embeddings)\n",
    "# save embeddings (for Tableau)\n",
    "abstract_df[\"x\"] = reduced_embeddings[:, 0]\n",
    "abstract_df[\"y\"] = reduced_embeddings[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f9b96345",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(result_path+'/LLM_en_openalex_title_embeddings_200.pickle', 'wb') as pkl:\n",
    "    pickle.dump(embeddings, pkl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6b52686d",
   "metadata": {},
   "outputs": [],
   "source": [
    "abstract_df.to_csv(data_export_path+\"/LLM_en_openalex_title_w_topics_years_positions_200.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3e20af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
